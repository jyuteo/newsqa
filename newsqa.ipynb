{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined-newsqa-data-v1.json', 'r') as f: \n",
    "    newsqa = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_dev_test(data_list):\n",
    "    train_list = list()\n",
    "    dev_list = list()\n",
    "    test_list = list()\n",
    "    for data in data_list['data']:\n",
    "        data_type = data['type']\n",
    "        if data_type == 'train':\n",
    "            train_list.append(data)\n",
    "        elif data_type == 'dev':\n",
    "            dev_list.append(data)\n",
    "        elif data_type == 'test':\n",
    "            test_list.append(data)\n",
    "        else:\n",
    "            raise Exception('%s' % data_type)\n",
    "    return train_list, dev_list, test_list\n",
    "\n",
    "train_news, dev_news, test_news = split_train_dev_test(newsqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11469\n",
      "638\n",
      "637\n"
     ]
    }
   ],
   "source": [
    "print(len(train_news))\n",
    "print(len(dev_news))\n",
    "print(len(test_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_list):\n",
    "    \n",
    "    contexts = list()\n",
    "    questions = list()\n",
    "    answers = list()\n",
    "    \n",
    "    for data in data_list:\n",
    "        text = data['text']\n",
    "        for question in data['questions']:\n",
    "            q = question['q']\n",
    "            for answer in question['answers']:\n",
    "                for sa in answer['sourcerAnswers']:\n",
    "                    start = sa.get('s', None)\n",
    "                    end = sa.get('e', None)\n",
    "                    if start is None or end is None:\n",
    "                        continue\n",
    "                    ans = {'answer_start': start,\n",
    "                           'answer_end': end}\n",
    "                    contexts.append(text)\n",
    "                    questions.append(q)\n",
    "                    answers.append(ans)\n",
    "    \n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301577\n",
      "301577\n",
      "301577\n"
     ]
    }
   ],
   "source": [
    "train_contexts, train_questions, train_answers = preprocess(train_news)\n",
    "print(len(train_contexts))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16858\n",
      "16858\n",
      "16858\n"
     ]
    }
   ],
   "source": [
    "dev_contexts, dev_questions, dev_answers = preprocess(dev_news)\n",
    "print(len(dev_contexts))\n",
    "print(len(dev_questions))\n",
    "print(len(dev_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16640\n",
      "16640\n",
      "16640\n"
     ]
    }
   ],
   "source": [
    "test_contexts, test_questions, test_answers = preprocess(test_news)\n",
    "print(len(test_contexts))\n",
    "print(len(test_questions))\n",
    "print(len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "dev_encodings = tokenizer(dev_contexts, dev_questions, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "        # if end position is None, the 'char_to_token' function points to the space before the correct token - > add + 1\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(dev_encodings, dev_answers)\n",
    "add_token_positions(test_encodings, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class NewsQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = NewsQADataset(train_encodings)\n",
    "dev_dataset = NewsQADataset(dev_encodings)\n",
    "test_dataset = NewsQADataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/18849 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train | Loss: 4.545799:   1%|          | 168/18849 [08:48<17:06:51,  3.30s/it]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dev_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "min_val_loss = np.Inf\n",
    "best_model_weight = copy.deepcopy(model.state_dict())\n",
    "min_val_epoch = 0\n",
    "\n",
    "loss_file_name = 'log/newsqa_log.csv'\n",
    "f = open(loss_file_name,'a')\n",
    "f.write('epoch, train loss, valid loss')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    for phase in ['Train', 'Valid']:\n",
    "        if phase == 'Train':\n",
    "            pbar = tqdm(train_loader)\n",
    "            model.train()\n",
    "        else: \n",
    "            pbar = tqdm(val_loader)\n",
    "            model.eval()\n",
    "            \n",
    "        for batch in pbar:            \n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs[0]\n",
    "            pbar.set_description('Epoch %d | %s | Loss: %f' % (epoch + 1, phase, loss.item()))\n",
    "            \n",
    "            if phase == 'Train':\n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            \n",
    "            else:\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "    if epoch == 0:\n",
    "        min_val_loss = val_loss / len(val_loader)\n",
    "    else:\n",
    "        if val_loss / len(val_loader) < min_val_loss:\n",
    "            best_model_weight = copy.deepcopy(model.state_dict())\n",
    "            min_val_loss = val_loss / len(val_loader)\n",
    "            min_val_epoch = epoch\n",
    "            torch.save(best_model_weight, 'models/newsqa_ep{}.pt'.format(min_val_epoch))\n",
    "            \n",
    "    f = open(loss_file_name,'a')\n",
    "    f.write(str((epoch+1)) + \", \" + str(train_loss/len(train_loader)) + \", \" + str(val_loss/len(val_loader)))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "print('Training completed')\n",
    "print('Minimum loss:', min_val_loss, 'in epoch', min_val_epoch)\n",
    "\n",
    "save_path = 'models/newsqa_ep{}.pt'.format(min_val_epoch)\n",
    "torch.save(best_model_weight, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"The US has passed the peak on new coronavirus cases, \" \\\n",
    "          \"President Donald Trump said and predicted that some states would reopen this month. \" \\\n",
    "          \"The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\"\n",
    "\n",
    "question = \"What was President Donald Trump's prediction?\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(question, context)\n",
    "\n",
    "input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "output = model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
    "start_scores = output.start_logits\n",
    "end_scores = output.end_logits\n",
    "\n",
    "ans_tokens = input_ids[torch.argmax(start_scores) : torch.argmax(end_scores)+1]\n",
    "answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\n",
    "\n",
    "print (\"\\nQuestion \",question)\n",
    "print (\"\\nAnswer Tokens: \")\n",
    "print (answer_tokens)\n",
    "\n",
    "answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "print (\"\\nAnswer : \",answer_tokens_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
